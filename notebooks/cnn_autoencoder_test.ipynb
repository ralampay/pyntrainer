{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys \n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '.'))\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '..'))\n",
    "from pyntrainer.lib.cnn_autoencoder import CnnAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default parameters\n",
    "img_width = 100\n",
    "img_height = 100\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        #print(filename)\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        img = cv2.resize(img, (img_width, img_height))\n",
    "        img = img / 255\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "images = load_images_from_folder(\"/home/ralampay/Desktop/train\")\n",
    "\n",
    "# Perform a transpose against numpy to be valid shape for tensor\n",
    "\n",
    "x = []\n",
    "\n",
    "for img in images:\n",
    "    img_tensor = torch.tensor(img.transpose((2,0,1))).float()\n",
    "    d = img_tensor.detach().numpy()\n",
    "    x.append(d)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnAutoencoder(\n",
      "  (convolutional_layers): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (deconvolutional_layers): ModuleList(\n",
      "    (0): ConvTranspose2d(8, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ConvTranspose2d(16, 3, kernel_size=(2, 2), stride=(2, 2))\n",
      "  )\n",
      "  (criterion): BCELoss()\n",
      ")\n",
      "=> Epoch: 1\tLoss: 0.63306\n",
      "=> Epoch: 2\tLoss: 0.18617\n",
      "=> Epoch: 3\tLoss: 0.13973\n",
      "=> Epoch: 4\tLoss: 0.13489\n",
      "=> Epoch: 5\tLoss: 0.12859\n",
      "=> Epoch: 6\tLoss: 0.12665\n",
      "=> Epoch: 7\tLoss: 0.12368\n",
      "=> Epoch: 8\tLoss: 0.12168\n",
      "=> Epoch: 9\tLoss: 0.11984\n",
      "=> Epoch: 10\tLoss: 0.12055\n",
      "=> Epoch: 11\tLoss: 0.11990\n",
      "=> Epoch: 12\tLoss: 0.11913\n",
      "=> Epoch: 13\tLoss: 0.12034\n",
      "=> Epoch: 14\tLoss: 0.11826\n",
      "=> Epoch: 15\tLoss: 0.12022\n",
      "=> Epoch: 16\tLoss: 0.11954\n",
      "=> Epoch: 17\tLoss: 0.12015\n",
      "=> Epoch: 18\tLoss: 0.11934\n",
      "=> Epoch: 19\tLoss: 0.11934\n",
      "=> Epoch: 20\tLoss: 0.11889\n",
      "=> Epoch: 21\tLoss: 0.11942\n",
      "=> Epoch: 22\tLoss: 0.11935\n",
      "=> Epoch: 23\tLoss: 0.12135\n",
      "=> Epoch: 24\tLoss: 0.11991\n",
      "=> Epoch: 25\tLoss: 0.11927\n",
      "=> Epoch: 26\tLoss: 0.11923\n",
      "=> Epoch: 27\tLoss: 0.11989\n",
      "=> Epoch: 28\tLoss: 0.11920\n",
      "=> Epoch: 29\tLoss: 0.12004\n",
      "=> Epoch: 30\tLoss: 0.11925\n",
      "=> Epoch: 31\tLoss: 0.11996\n",
      "=> Epoch: 32\tLoss: 0.12081\n",
      "=> Epoch: 33\tLoss: 0.11989\n",
      "=> Epoch: 34\tLoss: 0.11858\n",
      "=> Epoch: 35\tLoss: 0.11924\n",
      "=> Epoch: 36\tLoss: 0.11923\n",
      "=> Epoch: 37\tLoss: 0.11977\n",
      "=> Epoch: 38\tLoss: 0.11897\n",
      "=> Epoch: 39\tLoss: 0.12061\n",
      "=> Epoch: 40\tLoss: 0.11827\n",
      "=> Epoch: 41\tLoss: 0.11958\n",
      "=> Epoch: 42\tLoss: 0.11968\n",
      "=> Epoch: 43\tLoss: 0.11947\n",
      "=> Epoch: 44\tLoss: 0.11948\n",
      "=> Epoch: 45\tLoss: 0.11939\n",
      "=> Epoch: 46\tLoss: 0.11870\n",
      "=> Epoch: 47\tLoss: 0.11961\n",
      "=> Epoch: 48\tLoss: 0.11948\n",
      "=> Epoch: 49\tLoss: 0.11804\n",
      "=> Epoch: 50\tLoss: 0.11921\n",
      "=> Epoch: 51\tLoss: 0.11847\n",
      "=> Epoch: 52\tLoss: 0.11852\n",
      "=> Epoch: 53\tLoss: 0.11856\n",
      "=> Epoch: 54\tLoss: 0.11916\n",
      "=> Epoch: 55\tLoss: 0.11781\n",
      "=> Epoch: 56\tLoss: 0.11854\n",
      "=> Epoch: 57\tLoss: 0.11846\n",
      "=> Epoch: 58\tLoss: 0.11834\n",
      "=> Epoch: 59\tLoss: 0.11777\n",
      "=> Epoch: 60\tLoss: 0.11850\n",
      "=> Epoch: 61\tLoss: 0.11840\n",
      "=> Epoch: 62\tLoss: 0.11846\n",
      "=> Epoch: 63\tLoss: 0.12017\n",
      "=> Epoch: 64\tLoss: 0.11756\n",
      "=> Epoch: 65\tLoss: 0.11692\n",
      "=> Epoch: 66\tLoss: 0.11911\n",
      "=> Epoch: 67\tLoss: 0.11834\n",
      "=> Epoch: 68\tLoss: 0.11818\n",
      "=> Epoch: 69\tLoss: 0.11770\n",
      "=> Epoch: 70\tLoss: 0.11755\n",
      "=> Epoch: 71\tLoss: 0.11771\n",
      "=> Epoch: 72\tLoss: 0.11823\n",
      "=> Epoch: 73\tLoss: 0.11894\n",
      "=> Epoch: 74\tLoss: 0.11832\n",
      "=> Epoch: 75\tLoss: 0.11911\n",
      "=> Epoch: 76\tLoss: 0.11856\n",
      "=> Epoch: 77\tLoss: 0.12011\n",
      "=> Epoch: 78\tLoss: 0.11836\n",
      "=> Epoch: 79\tLoss: 0.11819\n",
      "=> Epoch: 80\tLoss: 0.11761\n",
      "=> Epoch: 81\tLoss: 0.11820\n",
      "=> Epoch: 82\tLoss: 0.11991\n",
      "=> Epoch: 83\tLoss: 0.11818\n",
      "=> Epoch: 84\tLoss: 0.11825\n",
      "=> Epoch: 85\tLoss: 0.11824\n",
      "=> Epoch: 86\tLoss: 0.11881\n",
      "=> Epoch: 87\tLoss: 0.11823\n",
      "=> Epoch: 88\tLoss: 0.11986\n",
      "=> Epoch: 89\tLoss: 0.11822\n",
      "=> Epoch: 90\tLoss: 0.11843\n",
      "=> Epoch: 91\tLoss: 0.11755\n",
      "=> Epoch: 92\tLoss: 0.11888\n",
      "=> Epoch: 93\tLoss: 0.11731\n",
      "=> Epoch: 94\tLoss: 0.11824\n",
      "=> Epoch: 95\tLoss: 0.11826\n",
      "=> Epoch: 96\tLoss: 0.11891\n",
      "=> Epoch: 97\tLoss: 0.11813\n",
      "=> Epoch: 98\tLoss: 0.11890\n",
      "=> Epoch: 99\tLoss: 0.11694\n",
      "=> Epoch: 100\tLoss: 0.11890\n",
      "=> Epoch: 101\tLoss: 0.11747\n",
      "=> Epoch: 102\tLoss: 0.11882\n",
      "=> Epoch: 103\tLoss: 0.11897\n",
      "=> Epoch: 104\tLoss: 0.11889\n",
      "=> Epoch: 105\tLoss: 0.11890\n",
      "=> Epoch: 106\tLoss: 0.11883\n",
      "=> Epoch: 107\tLoss: 0.11816\n",
      "=> Epoch: 108\tLoss: 0.11812\n",
      "=> Epoch: 109\tLoss: 0.11815\n",
      "=> Epoch: 110\tLoss: 0.11823\n",
      "=> Epoch: 111\tLoss: 0.11849\n",
      "=> Epoch: 112\tLoss: 0.11884\n",
      "=> Epoch: 113\tLoss: 0.11820\n",
      "=> Epoch: 114\tLoss: 0.11890\n",
      "=> Epoch: 115\tLoss: 0.11754\n",
      "=> Epoch: 116\tLoss: 0.11879\n",
      "=> Epoch: 117\tLoss: 0.11825\n",
      "=> Epoch: 118\tLoss: 0.11889\n",
      "=> Epoch: 119\tLoss: 0.11905\n",
      "=> Epoch: 120\tLoss: 0.11880\n",
      "=> Epoch: 121\tLoss: 0.11880\n",
      "=> Epoch: 122\tLoss: 0.11874\n",
      "=> Epoch: 123\tLoss: 0.11818\n",
      "=> Epoch: 124\tLoss: 0.11992\n",
      "=> Epoch: 125\tLoss: 0.11810\n",
      "=> Epoch: 126\tLoss: 0.11749\n",
      "=> Epoch: 127\tLoss: 0.11747\n",
      "=> Epoch: 128\tLoss: 0.11982\n",
      "=> Epoch: 129\tLoss: 0.11983\n",
      "=> Epoch: 130\tLoss: 0.11888\n",
      "=> Epoch: 131\tLoss: 0.11904\n",
      "=> Epoch: 132\tLoss: 0.11883\n",
      "=> Epoch: 133\tLoss: 0.11879\n",
      "=> Epoch: 134\tLoss: 0.11683\n",
      "=> Epoch: 135\tLoss: 0.11739\n",
      "=> Epoch: 136\tLoss: 0.11816\n",
      "=> Epoch: 137\tLoss: 0.11883\n",
      "=> Epoch: 138\tLoss: 0.11882\n",
      "=> Epoch: 139\tLoss: 0.11743\n",
      "=> Epoch: 140\tLoss: 0.11884\n",
      "=> Epoch: 141\tLoss: 0.11884\n",
      "=> Epoch: 142\tLoss: 0.11810\n",
      "=> Epoch: 143\tLoss: 0.11982\n",
      "=> Epoch: 144\tLoss: 0.11801\n",
      "=> Epoch: 145\tLoss: 0.11876\n",
      "=> Epoch: 146\tLoss: 0.11882\n",
      "=> Epoch: 147\tLoss: 0.11881\n",
      "=> Epoch: 148\tLoss: 0.11661\n",
      "=> Epoch: 149\tLoss: 0.11875\n",
      "=> Epoch: 150\tLoss: 0.11809\n",
      "=> Epoch: 151\tLoss: 0.11878\n",
      "=> Epoch: 152\tLoss: 0.11873\n",
      "=> Epoch: 153\tLoss: 0.11906\n",
      "=> Epoch: 154\tLoss: 0.11812\n",
      "=> Epoch: 155\tLoss: 0.11864\n",
      "=> Epoch: 156\tLoss: 0.11871\n",
      "=> Epoch: 157\tLoss: 0.11800\n",
      "=> Epoch: 158\tLoss: 0.11899\n",
      "=> Epoch: 159\tLoss: 0.11878\n",
      "=> Epoch: 160\tLoss: 0.11813\n",
      "=> Epoch: 161\tLoss: 0.11870\n",
      "=> Epoch: 162\tLoss: 0.12018\n",
      "=> Epoch: 163\tLoss: 0.11828\n",
      "=> Epoch: 164\tLoss: 0.11795\n",
      "=> Epoch: 165\tLoss: 0.11801\n",
      "=> Epoch: 166\tLoss: 0.11873\n",
      "=> Epoch: 167\tLoss: 0.11880\n",
      "=> Epoch: 168\tLoss: 0.11801\n",
      "=> Epoch: 169\tLoss: 0.11969\n",
      "=> Epoch: 170\tLoss: 0.11800\n",
      "=> Epoch: 171\tLoss: 0.11735\n",
      "=> Epoch: 172\tLoss: 0.11728\n",
      "=> Epoch: 173\tLoss: 0.11869\n",
      "=> Epoch: 174\tLoss: 0.11798\n",
      "=> Epoch: 175\tLoss: 0.11965\n",
      "=> Epoch: 176\tLoss: 0.11804\n",
      "=> Epoch: 177\tLoss: 0.11808\n",
      "=> Epoch: 178\tLoss: 0.11858\n",
      "=> Epoch: 179\tLoss: 0.11795\n",
      "=> Epoch: 180\tLoss: 0.11872\n",
      "=> Epoch: 181\tLoss: 0.11975\n",
      "=> Epoch: 182\tLoss: 0.11659\n",
      "=> Epoch: 183\tLoss: 0.11790\n",
      "=> Epoch: 184\tLoss: 0.11805\n",
      "=> Epoch: 185\tLoss: 0.11733\n",
      "=> Epoch: 186\tLoss: 0.11788\n",
      "=> Epoch: 187\tLoss: 0.11732\n",
      "=> Epoch: 188\tLoss: 0.11877\n",
      "=> Epoch: 189\tLoss: 0.11872\n",
      "=> Epoch: 190\tLoss: 0.11857\n",
      "=> Epoch: 191\tLoss: 0.11797\n",
      "=> Epoch: 192\tLoss: 0.11802\n",
      "=> Epoch: 193\tLoss: 0.11794\n",
      "=> Epoch: 194\tLoss: 0.11717\n",
      "=> Epoch: 195\tLoss: 0.11730\n",
      "=> Epoch: 196\tLoss: 0.11789\n",
      "=> Epoch: 197\tLoss: 0.11875\n",
      "=> Epoch: 198\tLoss: 0.11872\n",
      "=> Epoch: 199\tLoss: 0.11875\n"
     ]
    }
   ],
   "source": [
    "net = CnnAutoencoder(channel_maps=[3,16,8], img_width=img_width, img_height=img_height)\n",
    "print(net)\n",
    "net.fit(torch.tensor(x), lr=0.005, batch_size=50, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.errors(torch.tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net.forward(torch.tensor(x))\n",
    "\n",
    "err = nn.BCELoss(reduction='none')(y.view(-1, 3 * 100 * 100), torch.tensor(x).view(-1, 3 * 100 * 100)).mean(axis=1)\n",
    "err\n",
    "\n",
    "#for y_n in y:\n",
    "#    plt.imshow(y_n[0].detach(), cmap='gray')\n",
    "#    plt.show()\n",
    "#len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.predict(torch.tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_images_from_folder(\"/home/ralampay/Desktop/train\")\n",
    "\n",
    "# Perform a transpose against numpy to be valid shape for tensor\n",
    "\n",
    "x = []\n",
    "\n",
    "for img in images:\n",
    "    img_tensor = torch.tensor(img.transpose((2,0,1))).float()\n",
    "    d = img_tensor.detach().numpy()\n",
    "    x.append(d)\n",
    "\n",
    "y = net.forward(torch.tensor(x))\n",
    "for y_n in y:\n",
    "    plt.imshow(y_n[0].detach(), cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "y = net.predict(torch.tensor(x))\n",
    "print(y[y == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
